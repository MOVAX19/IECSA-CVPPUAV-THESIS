\chapter{Estado del Arte}

Las competencias de drones autónomos han adquirido un grado alto de relevancia en la última década, dentro del marco teórico del presente trabajo se describe con profundidad el contexto histórico, así como la motivación y los requerimientos establecidos para dos de las competencias, más significativas, de drones autónomos, el  IROS Autonomous Drone Race y el AlphaPilot AI Drone Innovation Challege. 
En este capítulo se presentan algunas de las soluciones propuestas en estas competencias, al igual que trabajos con enfoques más prácticos o que no se encuentran directamente relacionados con las carreras de drones autónomos.

Dentro de las competencias anteriormente mencionadas, existen dos problemas esenciales a los que se enfrentan los equipos que participan en estos retos, la detección de objetos y la gestión de trayectoria de vuelo a partir de la detección realizada. 
Los circuitos que tiene que completar los drones están compuestos por compuertas de distintas formas y tamaños, y en algunos casos, se adicionan obstáculos dinámicos, los vehículos desarrollados por los participantes tienen que ser capaces de detectar estos objetos haciendo uso exclusivo de los sensores con los que están equipados (cámaras, sensores ultrasónicos, tecnología láser, etc.).

Con base en lo anterior, Cabrera et al.(2019). \cite{cabrera2019gate} desarrollaron un algoritmo para la detección de compuertas en tiempo real basado en aprendizaje profundo. Su implementación se basó en una arquitectura de red neuronal convolucional con una arquitectura base de Single Shot Detector de 7 capas (SSD7\cite{SSD7}). La arquitectura base tiene un diseño optimizado para la detección de objetos, permitiendo un tiempo de entrenamiento reducido y una velocidad de detección alta; esta se modificó de tal forma que se eliminaron las últimas dos capas convoluciones, haciendo posible una detección mucho más rápida que la propuesta base y disminuyendo la complejidad de la red. El entrenamiento de la red se realizó con un total de 3418 imágenes obtenidas a partir de un entorno simulado y entornos reales. 
Además, para observar el desempeño de su implementación compararon su arquitectura con otras propuestas, SSD7, SSD300 y SmallerVGG, en simulaciones y ambientes de exteriores e interiores. Los resultados muestran que su propuesta logra un tiempo de detección promedio más bajo y porcentaje de confianza más alto que las otras arquitecturas. 

Por otro lado, Mellinger y Kumar (2011)\cite{mellinger2011minimum} presentaron un diseño de control y generación de trayectoria de vuelo en ambientes de interiores para un quadrotor. Su implementación es capaz de generar una trayectoria óptima y ángulos para la guiñada del vehículo, en tiempo real, a partir de matrices de rotación para el marco de referencia del vehículo y una secuencia de posiciones en tres dimensiones. La propuesta fue diseñada con el objetivo de que el quadrotor sea capaz de navegar de forma segura a través de corredores angostos, manteniéndose en los límites de velocidad y aceleración. Además, implementaron un control no lineal que asegura el seguimiento de las trayectorias generadas; las propuestas se pusieron a prueba con un prototipo físico  que se hizo volar a través de un circuito construido por aros, los cuales indicaban la trayectoria que el quadrotor debía de seguir.

A demás, Mueller et al.(2013)\cite{mueller2013computationally} diseñaron un algoritmo de bajo consumo computacional para la generación de trayectorias de intersección vuelo de un quadrotor. La implementación tuvo como propósito que el quadrotor fuera capaz de interceptar una pelota en vuelo, con una raqueta montada en su chasis. El algoritmo de generación de trayectoria se usó en un sistema de control predictivo, en donde miles de trayectorias eran generadas y evaluadas por el controlador, y después, la trayectoria más óptima era seleccionada por el algoritmo.  Se destaca el bajo coste computacional pues se utilizó el hardware de una laptop estándar para evaluar cerca de un millón de trayectorias por segundo.

Las propuestas anteriores representan ejemplos de soluciones individuales para cada uno de los problemas mencionados. Sin embargo, existen implementaciones que solucionan ambos problemas en un solo trabajo, y corresponden a aquellas que fueron desarrolladas como propuestas para participar en las competencias.

El trabajo realizado por Moon et al.(2019) \cite{moon2019challenges} compila una serie de propuestas destacadas, y describe con detalle los algoritmos de visión artificial, odometría, control de vuelo, etc. Desarrollados para el IROS 2017 por los equipos más sobresalientes de la competencia. 

Se presentan 5 propuestas distintas \cite{moon2019challenges}. Iniciando por el equipo ganador de la competencia, el equipo del Instituto Nacional de Astrofísica, Óptica y Electrónica (INAOE); implementaron un control PID para la altura, curso y ángulo de deslizamiento del dron, además, obtuvieron la localización espacial del dron y su orientación a partir de un algoritmo de  deep learning basado en ORB-SLAM. Su algoritmo de odometría asume que el suelo de la pista es plano, por lo que al conocer la altura y ángulo de la cámara de vuelo, les fue posible generar una trayectoria de vuelo adecuada para el cruce de las compuertas. 


Por otro lado, el equipo de la Universidad de Zurich (UZH) propuso una solución basada en la elaboración de un modelo 3D del circuito de vuelo, el cual utilizó para definir una serie de waypoint para la navegación del dron, a cada waypoint se le asoció un vector de velocidad; lo anterior en conjunto con un sistema de odometría visual, permitieron que el dron del equipo de UZH navegara de forma autónoma a través del circuito. 
El principal reto para esta implementación fue la alineación de la pista con el marco de referencia del dron, para solucionar lo anterior, utilizaron  un sensor de profundidad junto con un mapa de referencia, de tal forma que minimizan la distancia entre la nube de puntos de la pista y el conjunto de puntos proveídos por el sensor.

El tercer lugar del IROS 2017, le perteneció a la Universidad Técnica de Delft (TU Delft). Este equipo buscó enfocar su propuesta en drones de tamaño compacto (< 50 cm), teniendo como objetivo un vuelo rápido, ágil y de bajo costo computacional. Lo anterior contempla ciertas limitaciones inherentes en cuanto a la cantidad de sensores integrados en el vehículo y la gama de la computadora de vuelo que se puede utilizar.
Debido a lo anterior, el equipo TU Delft optó por utilizar una máquina de estados para la gestión de la trayectoria de vuelo, en vez de algoritmos complejos de SLAM u odometría visual. El algoritmo propuesto fue una máquina de estados de alto nivel en donde cada estado está asociado a un comportamiento específico definido para cada parte del circuito; esto representa una ventaja, pues la máquina de estados es muy eficiente, computacionalmente hablando. 
Por otro lado, la máquina de estados necesita la posición y orientación del dron con respecto a la compuerta que está a punto de cruzar; la detección de compuerta se realizó utilizando un algoritmo basado en la detección del color de estas. A partir de lo anterior, se detectó las esquinas de las compuertas, y utilizando la geometría conocida de las mismas, fue posible determinar la posición y orientación con respecto a la compuerta.

Después, el equipo del Instituto Avanzado de Ciencia y Tecnología de Corea (KAIST) propuso una combinación de una arquitectura de deep learning para la detección de compuertas y un algoritmo de guía por línea de vista (LOS Guidance) para la generación de la trayectoria de vuelo.
 El equipo KAIST implementó una red neuronal convolucional de 7 capas convolucionales, basada en la arquitectura de ADRNet, para el procesamiento de imágenes y la detección de compuertas en tiempo real. Esta arquitectura logró la inferencia a una velocidad de 28.95 fps en una computadora de placa única NVIDIA TX2. 
Por otro lado, KAIST logró la generación de maniobras precisas para el pase a través de compuerta con un algoritmo de LOS Guidance. Este algoritmo es muy utilizado en aeronaves de ala fija, y fue modificado ligeramente para que se adaptara a la dinámica de un quadrotor.
La propuesta desarrollada por KAIST representa una buen acercamiento para navegar en situaciones de alta incertidumbre, pues no depende en el mapa del mapa del circuito; sin embargo, lo anterior es ineficiente, computacionalmente hablando, circuitos en donde se cuenta con los detalles y composición del circuito de vuelo a priori.

Por último, en cuanto al IROS 2017, el equipo de la Universidad Nacional de Ulsan (UNIST) implementó una red neuronal profunda para la detección de las compuertas del circuito, y a partir del procesamiento de las imágenes, lograron generar controles de vuelo para el desplazamiento horizontal, vertical y las acciones rotacionales. Los comandos de vuelo son generados en forma de un mensaje de tipo MAVLink para que la computadora de vuelo los pueda interpretar, controlado el dron de forma directa.
La arquitectura de la red neuronal está basada en la red Google Inception, la cual representa el estado del arte de las arquitecturas para detección y clasificación. 
Bajo esta implementación, el dron es capaz de volar a través de las compuertas con dos pasos; el dron se encuentra en un posición inicial y su cámara tiene que tener en su campo de visión a la compuerta a travesar, se establece una línea recta con respecto al centro de la compuerta y el dron vuelo tomando esa trayectoria como referencia, una vez alineado con la recta, el dron vuelo a través del centro de la compuerta.


Por ejemplo, Kaufmann et al. (2018) \cite{kaufmann2018deep} desarrollaron un sistema de visión artificial y seguimiento de trayectoria, pensado para ambiente dinámicos, en donde se requiere de un vuelo ágil y una estimación de estados adecuada, que permita una rápida y correcta definición de la trayectoria de vuelo para el dron. 
Para lograr lo anterior, implementaron una red neuronal convolucional basada en la RedNet de Loquercio et al.(2018)\cite{loquercio2018dronet}, acoplada a un algoritmo de planificación de trayectoria; la red neuronal recibe imágenes directamente de la cámara de vuelo del dron y realiza un mapeo de tal forma que genera un waypoint y una referencia de velocidad deseada, lo es utilizado posteriormente por un algoritmo planificador para generar el segmento de trayectoria más corto y los comandos para los motores, de tal forma que el dron pueda alcanzar su destino. Esta implementación no requirió del conocimiento previo del circuito de vuelo, pues todos los cálculos son realizados en tiempo real durante el vuelo. Esta propuesta se implementó en simulación y en un ambiente físico en donde algunas de las compuertas del circuito cambiaban de posición durante el vuelo, además, su desempeño se comparó con el obtenido con un vuelo realizado por pilotos con distinta experiencia de vuelo. Por último, los resultados muestran que este sistema tuvo un desempeño más bajo en comparación con la habilidad y destreza de los pilotos humanos; sin embargo, este sistema ejemplifica una buena implementación de un algoritmo de percepción robusto en conjunto con una arquitectura moderna de machine learning y algoritmos de velocidad y estabilidad de vuelo. 